% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/simBulk.R
\name{simBulkProfiles}
\alias{simBulkProfiles}
\title{Simulate training and test simulated bulk RNA-seq samples}
\usage{
simBulkProfiles(
  object,
  type.data = "both",
  file.backend = NULL,
  compression.level = NULL,
  block.processing = FALSE,
  block.size = 1000,
  chunk.dims = NULL,
  threads = 1,
  verbose = TRUE
)
}
\arguments{
\item{object}{\code{\linkS4class{DigitalDLSorter}} object with
\code{single.cell.real}/\code{single.cell.simul} and \code{prob.cell.types}
slots.}

\item{type.data}{Type of data to generate among \code{'train'}, \code{'test'}
or \code{'both'} (the last by default).}

\item{file.backend}{Valid file path where to store simulatede single-cell
expression profiles as HDF5 file (\code{NULL} by default). If provided,
data is stored in HDF5 files as back-end by using \pkg{DelayedArray},
\pkg{HDF5Array} and \pkg{rhdf5} packages instead of loaded in memory. This
is suitable for situations where you have large amount of data that cannot
be allocated in memory. Note that operations on this data will be carried
out by blocks (i.e subsets of determined size), which can lead to longer
execution times.}

\item{compression.level}{The compression level used if \code{file.backend} is
provided. It is an integer value between 0 (no compression) and 9 (highest
and slowest compression). See
\code{?\link[HDF5Array]{getHDF5DumpCompressionLevel}} from \pkg{HDF5Array}
package for more information.}

\item{block.processing}{Boolean indicating if data should be simulated by
blocks (only if \code{file.backend} is used). \code{FALSE} by default. This
functionality is suitable for cases where is not possible to allocate data
in memory and that exexcution times will be larger.}

\item{block.size}{Number of single-cell expression profiles that will be
simulated in each iteration during the process. Larger numbers resulting in
more memory usage but lesser times executions. Set according to your
computer resources (1000 by default).}

\item{chunk.dims}{Specifies the dimensions that HDF5 chunk will have. If
\code{NULL}, the default value is a vector of two items: the number of
genes considered by ZINB-WaVE model during the simulation and only one
sample in order to increase the read times in the following steps. Greater
number of columns written in each chunk can lead to larger read times.}

\item{threads}{Number of threads used during the generation of bulk samples
(1 by default). Set according to computational resources and avoid it if
\code{block.size} will be used.}

\item{verbose}{Show informative messages during the execution (\code{TRUE} by
default).}
}
\value{
A \code{\linkS4class{DigitalDLSorter}} object with \code{bulk.simul}
slot containing a list with one or two entries (depending on selected
\code{type.data} argument): \code{'train'} and \code{'test'}. Each entry
contains a \code{\link[SummarizedExperiment]{SummarizedExperiment}} object
with simulated bulk samples in \code{assay} slot, sample names in
\code{colData} slot and feature names in \code{rowData} slot.
}
\description{
Simulate training and test bulk RNA-seq profiles using cell composition
matrices built by \code{\link{generateBulkCellMatrix}} function. Samples are
generated under the assumption that the expression of gene \eqn{i} in bulk
sample \eqn{j} is given by the sum of expression levels of cell types
\eqn{X_{ijk}} that composed them weighted by the proportions of these cell
types \eqn{k} in each sample  In this case, this information is known from
cell composition matrix. In practice, as described in Torroja et al., 2019,
these profiles are generated by the summation of a number of cells from
different cell types determined by cell composition matrix. The number of
simulated bulk samples and the number of cells that compose each sample are
determined by \code{\link{generateBulkCellMatrix}} (see Documentation).
}
\details{
\pkg{digitalDLSorteR} allows the use of HDF5 files as back-end for storing
the resulting data using \pkg{DelayedArray} and \pkg{HDF5Array} packages.
This functionality allows you to work without keeping data loaded in memory,
which will be of vital importance during some computationally heavy steps
such as neural network training. You must provide a valid file path in
\code{file.backend} argument to store the resulting file with '.h5'
extension. Data will be accessible from R without being loaded in memory.
This option slightly slows down execution times, since subsequent
transformations of data will be carried out by blocks instead of using all
data. We recommend this option according to the computational resources
available and the number of bulk samples that will be generated.

Note that if you use \code{file.backend} argument with \code{block.processing
= FALSE}, all bulk profiles will be simulated in one step and, therefore,
allocated in RAM memory. Then, data will be written in HDF5 file. In order to
avoid collapsing RAM memory, single-cell profiles will be simulated and
written in HDF5 files by blocks of \code{block.size} size by setting
\code{block.processing = TRUE}.

It is possible to avoid this step by using \code{on.the.fly} argument in
\code{\link{trainDigitalDLSorterModel}} function. By this way, data is
generated on the fly during the neural network training. See
\code{?\link{trainDigitalDLSorterModel}} for details.
}
\examples{
## loading all data in memory
DDLSSmallCompleted <- generateBulkSamples(
  DDLSSmallCompleted,
  threads = 2,
  type.data = "both"
)

\dontrun{
## using HDF5 as backend
DDLSChung <- generateBulkSamples(
  DDLSChung,
  threads = 2,
  type.data = "both",
  file.backend = "DDLSChung.bulk.simul.h5"
)
}

}
\references{
Pagès H, Hickey wcfP, Lun A (2020). DelayedArray: A unified
framework for working transparently with on-disk and in-memory array-like
datasets. R package version 0.16.0.

Pagès H (2020). HDF5Array: HDF5 backend for DelayedArray objects. R package
version 1.18.0.
}
\seealso{
\code{\link{generateBulkCellMatrix}}
\code{\linkS4class{ProbMatrixCellTypes}}
\code{\link{trainDigitalDLSorterModel}}
}
